"""
1. Naive Bayes
- 적용 상황: 스팸 메일 분류, 감정 분석 등 기초적인 텍스트 분류 작업에 주로 사용됨.
- 장점: 학습 속도가 빠르며, 간단한 데이터에도 잘 작동.
- 단점: 피처 간 독립성 가정이 현실과 다를 경우 성능이 떨어질 수 있음.

2. RNN (Recurrent Neural Networks)
- 적용 상황: 시퀀스 데이터 분류, 자연어 생성, 기계 번역 등에 사용됨.
- 장점: 시퀀스의 순서 정보를 고려하여 분석할 수 있음.
- 단점: 긴 시퀀스를 처리할 때 기울기 소실 문제가 발생할 수 있음.

3. LSTM (Long Short-Term Memory)
- 적용 상황: RNN의 문제점을 해결하고자 사용되며, 음성 인식, 기계 번역, 감정 분석 등 다양한 분야에서 활용됨.
- 장점: 기울기 소실 문제를 해결하여 긴 시퀀스를 더 잘 처리.
- 단점: 모델의 복잡성과 연산 비용이 높음.

4. BERT (Bidirectional Encoder Representations from Transformers)
- 적용 상황: 텍스트 분류, 질문 응답, 개체명 인식 등 다양한 자연어 처리 작업에 사용됨.
- 장점: 양방향 문맥 정보를 활용하여 높은 성능을 달성.
- 단점: 큰 모델 규모와 높은 연산 비용, 미세조정이 필요할 수 있음.

5. FastText
- 적용 상황: 텍스트 분류, 단어 임베딩 등에 사용됨.
- 장점: 학습 속도가 빠르며, 단어 레벨이 아닌 n-gram 레벨로 분석이 가능.
- 단점: 어휘 외 단어(Out-Of-Vocabulary, OOV)에 대한 처리가 미흡할 수 있음.
"""
